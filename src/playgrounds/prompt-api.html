---
layout: playground.njk
title: Prompt API playground
shorttitle: Prompt
description: Prompt an on-device language model to generate text based on a description of what you want to write.
stylesheet: prompt-api.css
script: prompt-api.js
---

<div class="settings-row no-separator">
  <label for="prompt">Language model prompt</label>
  <textarea spellcheck="false" id="prompt" placeholder="Enter text to prompt the language model"></textarea>
</div>

<div class="settings-row">
  <label for="system-prompt">System prompt</label>
  <textarea spellcheck="false" id="system-prompt"
    placeholder="Enter instructions, guidelines, and any information for the language model"></textarea>
</div>

<details class="settings-row">
  <summary>Advanced</summary>
  <label for="initial-prompts">
    N-shot prompt instructions (<span class="example-link-in-label" id="n-shot-example">load an example</span>)
    <span role="tooltip" id="n-shot-tooltip" style="anchor-name:--nshot-anchor;">
      <span class="tooltip-content" style="position-anchor:--nshot-anchor;">
        N-shot prompting is a technique used to provide the model with a few examples of the desired input-output pairs.
      </span>
    </span>
  </label>
  <textarea spellcheck="false" id="initial-prompts" placeholder="Enter user/assistant interactions" aria-describedby="n-shot-tooltip" class="code"></textarea>

  <label for="response-schema">
    Response constraint schema (<span class="example-link-in-label" id="response-schema-example">load an example</span>)
    <span role="tooltip" id="response-schema-tooltip" style="anchor-name:--schema-anchor;">
      <span class="tooltip-content" style="position-anchor:--schema-anchor;">
        A JSON schema that's used to constrain the model's response.
      </span>
    </span>
  </label>
  <textarea spellcheck="false" id="response-schema" placeholder="Enter a JSON schema to constrain the output." aria-describedby="response-schema-tooltip" class="code"></textarea>
</details>

<div class="settings-row no-separator">
  <label for="top-k">
    TopK
    <span role="tooltip" id="top-k-tooltip" style="anchor-name:--topk-anchor;">
      <span class="tooltip-content" style="position-anchor:--topk-anchor;">
        TopK is a sampling method that selects the top K most likely next tokens from the model's output distribution.
        The model then samples from this subset of tokens to generate the next token in the sequence. This method can
        help to reduce the randomness of the generated text and make it more coherent.
      </span>
    </span>
  </label>
  <div class="slider">
    <input type="range" id="top-k" min="1" max="100" value="10" aria-describedby="top-k-tooltip">
    <input type="number" id="top-k-value" min="1" max="100" value="10" tabindex="-1">
  </div>
</div>

<div class="settings-row">
  <label for="temperature">
    Temperature
    <span role="tooltip" id="temperature-tooltip" style="anchor-name:--temp-anchor;">
      <span class="tooltip-content" style="position-anchor:--temp-anchor;">
        Temperature is a parameter that controls the randomness of the model's output. A lower temperature (e.g., 0.1)
        makes the model more deterministic and focused, while a higher temperature (e.g., 1.0) makes it more random and
        creative. Adjusting the temperature can help you find the right balance between coherence and creativity in the
        generated text.
      </span>
    </span>
  </label>
  <div class="slider">
    <input type="range" id="temperature" min="0" max="1.0" value="0.7" step="0.1"
      aria-describedby="temperature-tooltip">
    <input type="number" id="temperature-value" min="0" max="1.0" value="0.7" step="0.1" tabindex="-1">
  </div>
</div>

<div class="settings-row submit">
  <button class="ai-button" id="run">Prompt</button>
  <button id="stop">Stop</button>
</div>